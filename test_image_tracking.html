<!DOCTYPE html>
<html>
<script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
<!-- we import arjs version without NFT but with marker + location based support -->
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

<head>
    <link rel="stylesheet" href="styles/styles.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins">
</head>

<body>

    <button class="button">Info</button>

    <!-- a-frame scene -->
  <a-scene
  vr-mode-ui="enabled: false;"
  renderer="logarithmicDepthBuffer: true;"
  embedded arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"
>
  <!-- a-nft is the anchor that defines an Image Tracking entity -->
  <!-- on 'url' use the path to the Image Descriptors created before. -->
  <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
  <a-nft
    type="nft"
    url="patterns/pattern-sala-02.png"
    smooth="true"
    smoothCount="10"
    smoothTolerance=".01"
    smoothThreshold="5"
  >
      <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
      <a-entity
      position="0 0 0"
      scale="4 4 4"
      obj-model="obj: url(/media/dama.obj);mtl: url(/media/dama.mtl);"
      animation="property: rotation; dur: 6000; to: 0 360 0; loop: true; easing: linear;"
      > </a-entity>
  </a-nft>
  <!-- static camera that moves according to the device movemenents -->
  <a-entity camera></a-entity>
</a-scene>

</body>
</html>